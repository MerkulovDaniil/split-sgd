# -*- coding: utf-8 -*-
"""Upper_bound_impractice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/MerkulovDaniil/split-sgd/blob/master/Code/Upper_bound_impractice.ipynb

# Random matrices

## Two batches
"""

# import time
# import numpy as np
# from matplotlib import pyplot as plt
# import scipy.linalg
# from scipy.linalg import expm
# import copy
# np.random.seed(0)

# def commutator(A1, A2):
#     return A1 @ A2 - A2 @ A1

# def log_norm(A):
#     w,v = np.linalg.eig((A + A.T)/2)
#     mu = np.round(max(w), 14)
#     return max(w) 

# def sheng_upper_bound(t, A1, A2):
#     mu1 = log_norm(A1)
#     mu2 = log_norm(A2)
#     return t**2/2 * np.linalg.norm(commutator(A1, A2), ord=2)*np.exp((mu1 + mu2)*t)

# def true_error(t, A1, A2):
#     return np.linalg.norm(expm((A1 + A2)*t) - expm(A1*t) @ expm(A2*t), ord=2)

# def generate_problem(p, n):
#     X = np.random.randn(n, p)

#     # Model definition
#     theta_clean = np.ones(p)
#     y = X @ theta_clean + 5e-1*np.random.randn(n) # right-hand side
#     theta_0 = np.random.randn(p)

#     return X, theta_0, y

# def plot_errors(errors_list, label_list, t):
#     plt.figure(figsize = (4,2.5))
#     linestyles = ['-', '--', ':', '-.']
#     for errors, label, style in zip(errors_list, label_list, linestyles):
#         plt.semilogy(t, errors, style, label=label)
    
#     legend_x = 0.4
#     legend_y = 0.6
#     plt.legend(bbox_to_anchor=(legend_x, legend_y))
#     plt.xlabel('t')
#     plt.ylabel('Norm of the error')
#     plt.grid(True, linestyle='--', linewidth=0.4)
#     plt.tight_layout()
#     plt.savefig('upper_bound_2.pdf')
#     plt.show()

# def plot_calculated_constant(X1, X2):
#     Q1, R1 = np.linalg.qr(X1.T)
#     Q2, R2 = np.linalg.qr(X2.T)
#     p, b = Q1.shape
#     return np.linalg.norm((np.eye(p) - Q1@Q1.T)@(np.eye(p) - Q2@Q2.T), ord=2)

# p = 100
# n = 100
# N = 2
# b = 50

# X, theta_0, y = generate_problem(p,n)

# Xs = np.zeros((N, b, p))
# ys = np.zeros((N, b))

# for i_batch in range(N):
#     Xs[i_batch] = X[b*i_batch:b*(i_batch+1), :] 
#     ys[i_batch] = y[b*i_batch:b*(i_batch+1)]

# A1 = -1/n*Xs[0].T @ Xs[0]
# A2 = -1/n*Xs[1].T @ Xs[1]

# ts = np.linspace(0,15)
# sheng_errors = [sheng_upper_bound(t, A1, A2) for t in ts]
# true_errors  = [true_error(t, A1, A2)        for t in ts]
# constant     = plot_calculated_constant(Xs[0], Xs[1])
# constants    = [constant                     for t in ts]

# plot_errors([true_errors, constants, sheng_errors], ['True error', 'Proposed upper bound','Sheng upper bound'], ts)

# """## Many batches"""

# import time
# import numpy as np
# from matplotlib import pyplot as plt
# import scipy.linalg
# from scipy.linalg import expm
# import copy
# from random import shuffle
# from tqdm import tqdm
# np.random.seed(0)


# def true_error(t, As):
#     # placeholder for the summand matrix and approximate solution
#     A               = np.zeros(As[0].shape)
#     approximation   = np.eye(len(As[0]))
#     for A_i in As:
#         A               += A_i
#         approximation   = approximation @ expm(A_i*t)
#     true_solution = expm(A*t)
#     return np.linalg.norm(true_solution - approximation, ord=2)

# def generate_problem(p,n,s):
#     X = np.random.randn(n, p)

#     # Model definition
#     theta_clean = np.ones(p)
#     y = X @ theta_clean + 5e-1*np.random.randn(n) # right-hand side
#     theta_0 = np.random.randn(p)

#     b = int(n // s)
#     Xs = np.zeros((s, b, p))
#     ys = np.zeros((s, b))

#     As = []
#     for i_batch in range(s):
#         Xs[i_batch] = X[b*i_batch:b*(i_batch+1), :] 
#         ys[i_batch] = y[b*i_batch:b*(i_batch+1)]
#         As.append(-1/n*Xs[i_batch].T @ Xs[i_batch])

#     return As, Xs

# def plot_errors(errors_list, label_list, t, title=''):
#     linestyles = ['-', '--', ':', '-.']
#     plt.figure(figsize = (4,2.5))
#     for errors, label, style in zip(errors_list, label_list, linestyles):
#         plt.semilogy(t, errors, style, label=label)
    
#     # legend_x = 0.4
#     # legend_y = 0.6
#     # plt.legend(bbox_to_anchor=(legend_x, legend_y))
#     plt.legend()
#     plt.xlabel('t')
#     plt.ylabel('Norm of the error')
#     plt.grid(True, linestyle='--', linewidth=0.4)
#     plt.tight_layout()
#     plt.savefig('upper_bound_many.pdf')
#     plt.show()

# def plot_calculated_constant(Xs):
#     b, p = Xs[0].shape
#     error_product = np.eye(p)
#     for X_i in Xs:
#         Q_i, R_i = np.linalg.qr(X_i.T)
#         projector_i = (np.eye(p) - Q_i@Q_i.T)
#         error_product = error_product @ projector_i
  
#     return np.linalg.norm(error_product, ord=2)

# p = 200
# n = 200
# s = 40

# As, Xs = generate_problem(p,n,s)

# ts = np.linspace(0,20)
# true_errors  = [true_error(t, As)   for t in ts]
# constant     = plot_calculated_constant(Xs)
# constants    = [constant            for t in ts]

# plot_errors([true_errors, constants], ['True error', 'Calculated upper bound'], ts, title=r'Linear System {} $\times$ {}, {} batches'.format(n,p,s))

# len(As)

# constants = []
# for i in tqdm(range(1000)):
#     perm = np.random.permutation(len(Xs))
#     constants.append(plot_calculated_constant(Xs[perm]))

# (max(constants) - min(constants))/min(constants)

"""# Tomography data

## Two batches
"""

import time
import numpy as np
from matplotlib import pyplot as plt
import scipy.linalg
from scipy.linalg import expm
import scipy.io as sio
import copy
np.random.seed(0)

def commutator(A1, A2):
    return A1 @ A2 - A2 @ A1

def log_norm(A):
    w,v = np.linalg.eig((A + A.T)/2)
    mu = np.round(max(w), 14)
    return max(w) 

def sheng_upper_bound(t, A1, A2):
    mu1 = log_norm(A1)
    mu2 = log_norm(A2)
    return t**2/2 * np.linalg.norm(commutator(A1, A2), ord=2)*np.exp((mu1 + mu2)*t)

def true_error(t, A1, A2):
    return np.linalg.norm(expm((A1 + A2)*t) - expm(A1*t) @ expm(A2*t), ord=2)

def load_tom_data(epsilon=1e-5):
    try:
        import google.colab
        # print('You need to upload LLS data manually or run notebook locally :(')
        # return 0
    except:
        print(None)
    X = sio.loadmat("./lls_data/fanlinear.mat")["A"].toarray()
    theta_true = sio.loadmat("./lls_data/shepplogan.mat")["x"]
    n, p = X.shape
    y = np.squeeze(X @ theta_true)
    return X, theta_true, y

def plot_errors(errors_list, label_list, t):
    plt.figure(figsize = (4,2.5))
    linestyles = ['-', '--', ':', '-.']
    for errors, label, style in zip(errors_list, label_list, linestyles):
        plt.semilogy(t, errors, style, label=label)
    
    legend_x = 0.4
    legend_y = 0.6
    plt.legend(bbox_to_anchor=(legend_x, legend_y))
    plt.xlabel('t')
    plt.ylabel('Norm of the error')
    plt.grid(True, linestyle='--', linewidth=0.4)
    plt.tight_layout()
    plt.savefig('upper_bound_2.pdf')
    plt.show()

def plot_calculated_constant(X1, X2):
    Q1, R1 = np.linalg.qr(X1.T)
    Q2, R2 = np.linalg.qr(X2.T)
    p, b = Q1.shape
    return np.linalg.norm((np.eye(p) - Q1@Q1.T)@(np.eye(p) - Q2@Q2.T), ord=2)

X, theta_0, y = load_tom_data()

n, p = X.shape
b    = int(n//2)
N    = 2

Xs = np.zeros((N, b, p))
ys = np.zeros((N, b))

for i_batch in range(N):
    Xs[i_batch] = X[b*i_batch:b*(i_batch+1), :] 
    ys[i_batch] = y[b*i_batch:b*(i_batch+1)]

A1 = -1/n*Xs[0].T @ Xs[0]
A2 = -1/n*Xs[1].T @ Xs[1]

ts = np.linspace(0,15)
sheng_errors = [sheng_upper_bound(t, A1, A2) for t in ts]
true_errors  = [true_error(t, A1, A2)        for t in ts]
constant     = plot_calculated_constant(Xs[0], Xs[1])
constants    = [constant                     for t in ts]

plot_errors([true_errors, constants, sheng_errors], ['True error', 'Proposed upper bound','Sheng upper bound'], ts)

"""## Many batches"""

import time
import numpy as np
from matplotlib import pyplot as plt
import scipy.linalg
from scipy.linalg import expm
import copy
from random import shuffle
from tqdm import tqdm
np.random.seed(0)


def true_error(t, As):
    # placeholder for the summand matrix and approximate solution
    A               = np.zeros(As[0].shape)
    approximation   = np.eye(len(As[0]))
    for A_i in As:
        A               += A_i
        approximation   = approximation @ expm(A_i*t)
    true_solution = expm(A*t)
    return np.linalg.norm(true_solution - approximation, ord=2)

def load_tom_data_batched(s):
    try:
        import google.colab
        # print('You need to upload LLS data manually or run notebook locally :(')
        # return 0
    except:
        print(None)
    X = sio.loadmat("./lls_data/fanlinear.mat")["A"].toarray()
    theta_true = sio.loadmat("./lls_data/shepplogan.mat")["x"]
    n, p = X.shape
    y = np.squeeze(X @ theta_true)
    b = int(n // s)
    Xs = np.zeros((s, b, p))
    ys = np.zeros((s, b))

    As = []
    for i_batch in range(s):
        Xs[i_batch] = X[b*i_batch:b*(i_batch+1), :] 
        ys[i_batch] = y[b*i_batch:b*(i_batch+1)]
        As.append(-1/n*Xs[i_batch].T @ Xs[i_batch])

    return As, Xs

def plot_errors(errors_list, label_list, t, title=''):
    linestyles = ['-', '--', ':', '-.']
    plt.figure(figsize = (4,2.5))
    for errors, label, style in zip(errors_list, label_list, linestyles):
        plt.semilogy(t, errors, style, label=label)
    
    # legend_x = 0.4
    # legend_y = 0.6
    # plt.legend(bbox_to_anchor=(legend_x, legend_y))
    plt.legend()
    plt.xlabel('t')
    plt.ylabel('Norm of the error')
    plt.grid(True, linestyle='--', linewidth=0.4)
    plt.tight_layout()
    plt.savefig('upper_bound_many.pdf')
    plt.show()

def plot_calculated_constant(Xs):
    b, p = Xs[0].shape
    error_product = np.eye(p)
    for X_i in Xs:
        Q_i, R_i = np.linalg.qr(X_i.T)
        projector_i = (np.eye(p) - Q_i@Q_i.T)
        error_product = error_product @ projector_i
  
    return np.linalg.norm(error_product, ord=2)

s = 40

As, Xs = load_tom_data_batched(s)
N, b, p = Xs.shape

ts = np.linspace(0,20)
true_errors  = [true_error(t, As)   for t in ts]
constant     = plot_calculated_constant(Xs)
constants    = [constant            for t in ts]

plot_errors([true_errors, constants], ['True error', 'Calculated upper bound'], ts, title=r'Linear System {} $\times$ {}, {} batches'.format(n,p,s))