{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Continious time.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzVMn7DLxB4KA81yoMwaOt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MerkulovDaniil/split-sgd/blob/master/Code/Continuous_time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yR8uSVLhSVKk"
      },
      "source": [
        "# Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kTO963H5Rpwh",
        "colab": {}
      },
      "source": [
        "# ======= Libraries =======\n",
        "\n",
        "import math\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"5\" # export OMP_NUM_THREADS=5\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"5\" # export OPENBLAS_NUM_THREADS=5\n",
        "os.environ[\"MKL_NUM_THREADS\"] = \"5\" # export MKL_NUM_THREADS=5\n",
        "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"5\" # export VECLIB_MAXIMUM_THREADS=5\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"5\" # export NUMEXPR_NUM_THREADS=5\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "from scipy.integrate import odeint, solve_ivp\n",
        "# from torchdiffeq import odeint\n",
        "from scipy.linalg import expm, qr\n",
        "import scipy.io as sio\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device('cuda')\n",
        "# else:\n",
        "device = torch.device('cpu')\n",
        "import copy\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "import random\n",
        "# Reproducibility\n",
        "random.seed(999)\n",
        "np.random.seed(999)\n",
        "torch.manual_seed(999)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o4tNM5LCs9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ======= Function definitions =======\n",
        "\n",
        "def load_tom_data(epsilon=1e-5):\n",
        "    X = sio.loadmat(\"./lls_data/fanlinear.mat\")[\"A\"].toarray()\n",
        "    theta_true = sio.loadmat(\"./lls_data/shepplogan.mat\")[\"x\"]\n",
        "    n, p = X.shape\n",
        "    y = np.squeeze(X @ theta_true)\n",
        "    return X, theta_true, y\n",
        "\n",
        "def generate_problem(p, n, lstsq=False, epsilon = 0):\n",
        "    X = np.random.randn(n, p)\n",
        "\n",
        "    # Model definition\n",
        "    theta_clean = np.ones(p)\n",
        "    y = X @ theta_clean + epsilon*np.random.randn(n) # right-hand side\n",
        "    init_bound = 1.0/math.sqrt(p)\n",
        "    theta_0 = np.array(init_bound*torch.FloatTensor(p).uniform_(-1, 1))\n",
        "\n",
        "    if lstsq == True:\n",
        "        theta_lstsq = np.linalg.lstsq(X,y)[0]\n",
        "        return X, theta_0, y, theta_lstsq\n",
        "    else:\n",
        "        return X, theta_0, y\n",
        "\n",
        "def solve_local_problem(Q, R, theta_0, y_batch, h, n):\n",
        "    try:\n",
        "        R_it = np.linalg.inv(R.T)\n",
        "    except np.linalg.LinAlgError as err:\n",
        "        # print(err)\n",
        "        R_it = np.linalg.pinv(R.T)\n",
        "    exp_m = expm(-1/n* R @ R.T*h)\n",
        "    return Q @ ( exp_m @ (Q.T @ theta_0 - R_it @ y_batch )) + Q @ (R_it @ y_batch) + theta_0 - Q @ (Q.T @ theta_0)\n",
        "\n",
        "def solve_local_problem_b_1(x, theta_0, y, h, n):\n",
        "    x = x.T\n",
        "    norm = x.T @ x\n",
        "    return theta_0 + (1 - np.exp(-norm*h/n))*(y - x.T @ theta_0)/norm*x\n",
        "\n",
        "def loss(X, theta, y):\n",
        "    '''\n",
        "    Supports batch reformulation. The difference in dimension of the input\n",
        "    '''\n",
        "    if len(X.shape) == 2:\n",
        "        n, p = X.shape\n",
        "        return 1/n*np.linalg.norm(X @ theta - y)**2\n",
        "    elif len(X.shape) == 3:\n",
        "        m, b, p = Xs.shape\n",
        "        n = b*m\n",
        "\n",
        "        loss = 0\n",
        "        for i_batch in range(m):\n",
        "            loss += 1/n*np.linalg.norm(X[i_batch] @ theta - y[i_batch])**2\n",
        "        return loss\n",
        "    else:\n",
        "        raise ValueError('ðŸ¤” Inappropriate format of dataset')\n",
        "\n",
        "def rel_residual(X, theta, y):\n",
        "    '''\n",
        "    Supports batch reformulation. The difference in dimension of the input\n",
        "    '''\n",
        "    if len(X.shape) == 2:\n",
        "        n, p = X.shape\n",
        "        return np.linalg.norm(X @ theta - y)/np.linalg.norm(y)\n",
        "    elif len(X.shape) == 3:\n",
        "        m, b, p = Xs.shape\n",
        "        n = b*m\n",
        "\n",
        "        loss = 0\n",
        "        y_full = np.zeros(n)\n",
        "        X_full = np.zeros((n, p))\n",
        "        for i_batch in range(m):\n",
        "            y_full[b*i_batch:b*(i_batch+1)]     = y[i_batch]\n",
        "            X_full[b*i_batch:b*(i_batch+1), :]  = X[i_batch]\n",
        "\n",
        "        return np.linalg.norm(X_full @ theta - y_full)/np.linalg.norm(y_full)\n",
        "    else:\n",
        "        raise ValueError('ðŸ¤” Inappropriate format of dataset')\n",
        "\n",
        "\n",
        "def gradient(X, theta, y):\n",
        "    '''\n",
        "    Supports batch reformulation. The difference in dimension of the input\n",
        "    '''\n",
        "    if len(X.shape) == 2:\n",
        "        n, p = X.shape\n",
        "        return 1/n* X.T @ (X @ theta - y)\n",
        "    elif len(X.shape) == 3:\n",
        "        m, b, p = Xs.shape\n",
        "        n = b*m\n",
        "\n",
        "        gradient = 0\n",
        "        for i_batch in range(m):\n",
        "            gradient += 1/n* X[i_batch].T @ (X[i_batch] @ theta - y[i_batch])\n",
        "        return gradient\n",
        "    else:\n",
        "        raise ValueError('ðŸ¤” Inappropriate format of dataset')\n",
        "\n",
        "def make_SGD_step(X_batch, theta_0, y_batch, lr):\n",
        "    theta = theta_0 - lr*gradient(X_batch, theta_0, y_batch)\n",
        "    return theta\n",
        "\n",
        "def sgd_training(theta_0, theta_lstsq, Xs, ys, lr, N_epochs = N_epochs):\n",
        "    m, b, p = Xs.shape\n",
        "    n = b*m\n",
        "    loss_sgd, grad_sgd, par_diff_sgd = [], [], []\n",
        "    theta_t = theta_0\n",
        "    for i_epoch in range(N_epochs):\n",
        "        loss_sgd.append(loss(Xs, theta_t, ys))\n",
        "        grad_sgd.append(np.linalg.norm(gradient(Xs, theta_t, ys)))\n",
        "        par_diff_sgd.append(np.linalg.norm(theta_t - theta_lstsq)/np.linalg.norm(theta_lstsq))\n",
        "        for i_batch in range(m):          \n",
        "            theta_t = make_SGD_step(Xs[i_batch], theta_t, ys[i_batch], lr)\n",
        "\n",
        "        sys.stdout.write('\\r'+f'ðŸ¤– SGD. Loss {loss_sgd[-1]:.3f}, Grad_norm {grad_sgd[-1]:.3f}, relpardiff {par_diff_sgd[-1]:.3f} after {i_epoch} epoch. Lr {lr}')\n",
        "\n",
        "    print('\\r'+f'ðŸ¤– SGD. Loss {loss_sgd[-1]:.3f}, Grad_norm {grad_sgd[-1]:.3f}, relpardiff {par_diff_sgd[-1]:.3f} after {i_epoch} epoch. Lr {lr}')    \n",
        "    return loss_sgd, grad_sgd, par_diff_sgd\n",
        "\n",
        "def gd_training(theta_0, theta_lstsq, X, y, total_time, stepsize):\n",
        "    n, p = X.shape\n",
        "    loss_gd, grad_gd, par_diff_gd = [], [], []\n",
        "    theta_t = theta_0\n",
        "    N_steps = int(total_time/stepsize)\n",
        "    for i_step in range(N_steps):\n",
        "        loss_gd.append(loss(X, theta_t, y))\n",
        "        grad_gd.append(np.linalg.norm(gradient(X, theta_t, y)))\n",
        "        par_diff_gd.append(np.linalg.norm(theta_t - theta_lstsq)/np.linalg.norm(theta_lstsq))\n",
        "                  \n",
        "        theta_t = theta_t - stepsize*gradient(X, theta_t, y)\n",
        "\n",
        "        sys.stdout.write('\\r'+f'ðŸ¤– GD. Loss {loss_gd[-1]:.3f}, Grad_norm {grad_gd[-1]:.3f}, relpardiff {par_diff_gd[-1]:.3f} after {i_step} step.')\n",
        "\n",
        "    print('\\r'+f'ðŸ¤– GD. Loss {loss_gd[-1]:.3f}, _gd_norm {grad_gd[-1]:.3f}, relpardiff {par_diff_gd[-1]:.3f} after {i_step} step.')    \n",
        "    return loss_gd, grad_gd, par_diff_gd\n",
        "\n",
        "def spl_training(theta_0, theta_lstsq, Qs, Rs, Xs, ys, stepsize, N_spl_steps = N_spl_steps):\n",
        "    m, b, p = Xs.shape\n",
        "    n = b*m\n",
        "    loss_spl, grad_spl, par_diff_spl = [], [], []\n",
        "    theta_t = theta_0\n",
        "    for i_step in range(N_spl_steps):         \n",
        "        i_batch = i_step % m\n",
        "        if i_batch == 0:\n",
        "            loss_spl.append(loss(Xs, theta_t, ys))\n",
        "            grad_spl.append(np.linalg.norm(gradient(Xs, theta_t, ys)))\n",
        "            par_diff_spl.append(np.linalg.norm(theta_t - theta_lstsq)/np.linalg.norm(theta_lstsq))\n",
        "            sys.stdout.write('\\r'+f'ðŸ¤– Splitting I. Loss {loss_spl[-1]:.3f}, Grad_norm {grad_spl[-1]:.3f}, relpardiff {par_diff_spl[-1]:.3f} after {i_step} epoch. Stepsize {stepsize}')\n",
        "\n",
        "        theta_t = solve_local_problem(Qs[i_batch], Rs[i_batch], theta_t, ys[i_batch], stepsize, n)\n",
        "    \n",
        "    print('\\r'+f'ðŸ¤– Splitting I. Loss {loss_spl[-1]:.3f}, Grad_norm {grad_spl[-1]:.3f}, relpardiff {par_diff_spl[-1]:.3f} after {i_step} steps. Stepsize {stepsize}')\n",
        "    return loss_spl, grad_spl, par_diff_spl\n",
        "\n",
        "def plot_continuous_time_lls(times, losses, grads, rel_diffs, labels, N_epochs, title = 'Linear least squares. Random'):\n",
        "    colors = ['r', 'g', 'b']\n",
        "    color_labels = ['^', 'o', '-']\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (9,3))\n",
        "    fig.suptitle(title)\n",
        "    for time, loss, grad, rel_diff, label, col, col_lab in zip(times, losses, grads, rel_diffs, labels, colors, color_labels):\n",
        "        ax1.semilogy(time, loss,     col+col_lab, label = label)\n",
        "        ax1.semilogy(time, loss,     col+':')\n",
        "        ax2.semilogy(time, grad,     col+col_lab, label = label)\n",
        "        ax2.semilogy(time, grad,     col+':')\n",
        "        ax3.semilogy(time, rel_diff, col+col_lab, label = label)\n",
        "        ax3.semilogy(time, rel_diff, col+':')\n",
        "    ax1.grid(True,which=\"both\", linestyle='--', linewidth=0.4)\n",
        "    ax1.set_title(r'$f(\\theta(t))$')\n",
        "    ax1.set_xlabel('t')\n",
        "    ax2.grid(True,which=\"both\", linestyle='--', linewidth=0.4)\n",
        "    ax2.set_title(r'$\\|\\nabla f(\\theta(t))\\|$')\n",
        "    ax2.set_xlabel('t')\n",
        "    ax3.grid(True,which=\"both\", linestyle='--', linewidth=0.4)\n",
        "    ax3.set_title(r'$\\frac{\\|\\theta(t) - \\theta_{LS}\\|}{\\|\\theta_{LS}\\|}$')\n",
        "    ax3.set_xlabel('t')\n",
        "    plt.legend()\n",
        "    fig.tight_layout()\n",
        "    # plt.savefig(title + '.pdf')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieEPs2uGRJ8k",
        "colab_type": "code",
        "outputId": "a918bae0-f24d-4e9b-fd49-0c7a960c408f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# ======= Problem generation =======\n",
        "\n",
        "# We fix best learning rate for the SGD and try different hs for the splitting. \n",
        "# Drawing 3 graphs in cont time (loss, grad_norm, norm of theparameter difference)\n",
        "\n",
        "p = 400\n",
        "n = 2000\n",
        "m = 100\n",
        "b = 20\n",
        "epsilon = 1e-1\n",
        "\n",
        "LEARNING_RATE = 10**(-1.5)\n",
        "N_epochs = 10\n",
        "h = LEARNING_RATE*m # with this values we have equal number of epochs\n",
        "# h = 10\n",
        "TOTAL_TIME = N_epochs*LEARNING_RATE*m\n",
        "GF_STEPSIZE   = 1e-4\n",
        "\n",
        "N_spl_epochs = int(np.floor(TOTAL_TIME/h))\n",
        "N_spl_steps  = N_spl_epochs*m\n",
        "\n",
        "LABELS = ['SGD', 'Splitting I']\n",
        "ts_sgd = np.linspace(0, TOTAL_TIME, int(N_epochs))\n",
        "ts_spl = np.linspace(0, N_spl_epochs*h, N_spl_epochs)\n",
        "ts_gd  = np.linspace(0, TOTAL_TIME, int(TOTAL_TIME/GF_STEPSIZE))\n",
        "\n",
        "# problems = ['tomography', 'random']\n",
        "# problems = ['tomography']\n",
        "problems = ['random']\n",
        "\n",
        "X, theta_0, y, theta_lstsq = generate_problem(p, n, lstsq=True, epsilon = epsilon)\n",
        "Xs = np.zeros((m, b, p))\n",
        "ys = np.zeros((m, b))\n",
        "Qs = np.zeros((m, p, b))\n",
        "Rs = np.zeros((m, b, b))\n",
        "Q, R = qr(X.T, mode='economic')\n",
        "\n",
        "for i_batch in range(m):\n",
        "    Xs[i_batch] = X[b*i_batch:b*(i_batch+1), :]\n",
        "    ys[i_batch] = y[b*i_batch:b*(i_batch+1)]\n",
        "    Qs[i_batch], Rs[i_batch] = qr(Xs[i_batch].T, mode='economic')\n",
        "\n",
        "loss_sgd, grad_sgd, par_diff_sgd = sgd_training(theta_0, theta_lstsq, Xs, ys, lr = LEARNING_RATE, N_epochs = N_epochs)\n",
        "loss_spl, grad_spl, par_diff_spl = spl_training(theta_0, theta_lstsq, Qs, Rs, Xs, ys, stepsize = h, N_spl_steps = N_spl_steps)\n",
        "loss_gd, grad_gd, par_diff_gd    = gd_training(theta_0,  theta_lstsq, X, y, total_time = TOTAL_TIME, stepsize = GF_STEPSIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ðŸ¤– SGD. Loss 0.011, Grad_norm 0.062, relpardiff 0.003 after 9 epoch. Lr 0.03162277660168379\n",
            "ðŸ¤– Splitting I. Loss 0.009, Grad_norm 0.045, relpardiff 0.002 after 999 steps. Stepsize 3.162277660168379\n",
            "ðŸ¤– GD. Loss 2.849, Grad_norm 1.229, relpardiff 0.121 after 32398 step."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pkYNOtYSLkR",
        "colab_type": "code",
        "outputId": "c2d566b3-ff85-4256-c25b-631d98594e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "times     = [ts_sgd, ts_spl, ts_gd]\n",
        "losses    = [loss_sgd, loss_spl, loss_gd]\n",
        "grads     = [grad_sgd, grad_spl, grad_gd]\n",
        "rel_diffs = [par_diff_sgd, par_diff_spl, par_diff_gd]\n",
        "labels    = ['SGD', 'Splitting I', 'GF Euler']\n",
        "title     = f'Random LLS. n={n}, b={b}, p={p}'\n",
        "plot_continuous_time_lls(times, losses, grads, rel_diffs, labels, N_epochs, title)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUj7vpueAXcR",
        "colab_type": "text"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMBsSRdy_YUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ======= Problem generation =======\n",
        "\n",
        "TARGET_ERROR    = 0.001\n",
        "N_EXPERIMENTS   = 30\n",
        "LEARNING_RATES  = np.array(np.logspace(-3, 2, 10))\n",
        "LEARNING_RATES  = np.append(LEARNING_RATES, np.array(np.logspace(2, 7, 6)))\n",
        "iter_limit      = 30000\n",
        "\n",
        "GD_N_iter     = np.zeros((N_EXPERIMENTS, len(LEARNING_RATES)))\n",
        "SGD_N_iter    = np.zeros((N_EXPERIMENTS, len(LEARNING_RATES)))\n",
        "SPL_N_iter    = np.zeros((N_EXPERIMENTS, len(LEARNING_RATES)))\n",
        "\n",
        "GD_time     = np.zeros((N_EXPERIMENTS, len(LEARNING_RATES)))\n",
        "SGD_time    = np.zeros((N_EXPERIMENTS, len(LEARNING_RATES)))\n",
        "SPL_time    = np.zeros((N_EXPERIMENTS, len(LEARNING_RATES)))\n",
        "\n",
        "# Problem generation\n",
        "batch_size = 50\n",
        "number_of_classes = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1nfnol5AeTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ======= Function definitions =======\n",
        "\n",
        "def sigmoid(x):\n",
        "    '''\n",
        "    Calculates element-wise sigmoid function\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : array-like of floats\n",
        "        Input vector (scalar)\n",
        "    Returns\n",
        "    -------\n",
        "    sigma(x) : array-like of floats\n",
        "        1/(1 + exp(-x_i)) for each x_i in x\n",
        "    '''\n",
        "    if np.isscalar(x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "    else:\n",
        "        return np.array([1/(1 + np.exp(-x_i)) for x_i in x])\n",
        "\n",
        "def make_splitting_step(Q, R, theta_0, y, h, n):\n",
        "    h_seq = [0, h]\n",
        "    eta_0 = Q.T@theta_0\n",
        "    def rhs(eta, t):\n",
        "        return -1/n * R@(sigmoid(R.T @ eta) - np.array(y))\n",
        "    eta_h = odeint(rhs, eta_0, h_seq)[-1]\n",
        "\n",
        "    theta = Q@(eta_h - eta_0) + theta_0\n",
        "    return theta\n",
        "\n",
        "def load_batched_data_epi(batch_size=50, shuffle = True, qr_mode = False, number_of_classes = 2):\n",
        "    data = pd.read_csv('logreg/data.csv')\n",
        "    print(f'Before pruning {data.shape}')\n",
        "    data = data.dropna()\n",
        "    y = data['y']\n",
        "    X = data.drop(data.columns[0], axis=1)\n",
        "    X = X.drop(columns=['y'])\n",
        "    select_binary = (y == 2) + (y == 1)\n",
        "    X, y = X[select_binary], y[select_binary]\n",
        "    print(f'After pruning {data.shape}, {X.shape}, {y.shape}')\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "    n_train, p = X_train.shape\n",
        "    n_test  = len(y_test)\n",
        "\n",
        "    s_train = int(n_train/batch_size)   # Number of training batches\n",
        "\n",
        "    K           = number_of_classes \n",
        "    X_trains    = torch.zeros((s_train, batch_size, p), requires_grad=False).to(device)\n",
        "    y_trains    = torch.zeros((s_train, batch_size), requires_grad=False).to(device)\n",
        "    if qr_mode:\n",
        "        Qs      = torch.zeros((s_train, p, batch_size), requires_grad=False).to(device)\n",
        "        Rs      = torch.zeros((s_train, batch_size, batch_size), requires_grad=False).to(device)\n",
        "        print('ðŸ¤–QR started')\n",
        "\n",
        "    for i in range(s_train):\n",
        "        X_trains[i] = torch.from_numpy(X_train[batch_size*i:batch_size*(i+1)].to_numpy())\n",
        "        y_trains[i] = torch.from_numpy(y_train[batch_size*i:batch_size*(i+1)].to_numpy())\n",
        "        if qr_mode:\n",
        "            Qs[i], Rs[i] = torch.qr(X_trains[i].t())      \n",
        "    print(type(X_trains), type(y_trains), type(X_test), type(y_test), type(Qs), type(Rs))        \n",
        "    if qr_mode:\n",
        "        print('âœ…QR computed')\n",
        "        return X_trains, y_trains, torch.from_numpy(X_test.to_numpy()), torch.from_numpy(y_test.to_numpy()), Qs, Rs\n",
        "    else:\n",
        "        return X_trains, y_trains, torch.from_numpy(X_test.to_numpy()), torch.from_numpy(y_test.to_numpy())\n",
        "\n",
        "\n",
        "def load_batched_data(batch_size=50, shuffle = True, qr_mode = False, number_of_classes = 2):\n",
        "    '''\n",
        "    Load batches of MNIST data.\n",
        "\n",
        "    Output: X_trains - s_train batches of training data, \n",
        "            y_trains - s_train batches of labels,\n",
        "            X_test - test points\n",
        "            y_test - test labels\n",
        "    X_trains: torch.array of shape (s_train,batch_size,*X_train[0].shape),\n",
        "        where \n",
        "        s_train - the number of batches, \n",
        "        batch_size - batch size\n",
        "        *X_train[0].shape - shape of the dataset point;\n",
        "\n",
        "    y_trains: torch.array of shape (s_train, K, batch_size),\n",
        "        where\n",
        "        K - the number of classes in the problem;\n",
        "\n",
        "    X_test: torch.array of shape (n_test,*X_train[0].shape),\n",
        "        where\n",
        "        n_test - the number of test points;\n",
        "\n",
        "    y_test: torch.array of shape (K, n_test);\n",
        "    '''\n",
        "    trainset = datasets.MNIST('./mnist_data/', download=True, train=True)\n",
        "    X_train = trainset.train_data.to(dtype=torch.float)/255\n",
        "    y_train = trainset.train_labels\n",
        "    mask    = y_train < number_of_classes\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    X_train.resize_(len(X_train), *X_train[0].view(-1).shape)\n",
        "    y_train.view(-1).long()\n",
        "\n",
        "    if shuffle == True:\n",
        "        shuffling = torch.randperm(len(y_train))\n",
        "        X_train = X_train[shuffling]\n",
        "        y_train = y_train[shuffling]\n",
        "\n",
        "    # Download and load the test data\n",
        "    testset = datasets.MNIST('./mnist_data/', download=True, train=False)\n",
        "    X_test = testset.test_data.to(dtype=torch.float)/255\n",
        "    y_test = testset.test_labels\n",
        "    mask   = y_test < number_of_classes\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "    X_test.resize_(len(X_test), *X_test[0].view(-1).shape)\n",
        "    y_test.view(-1).long()\n",
        "\n",
        "    if shuffle == True:\n",
        "        shuffling = torch.randperm(len(y_test))\n",
        "        X_test = X_test[shuffling].to(device)\n",
        "        y_test = y_test[shuffling]\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    n_test  = len(y_test)\n",
        "\n",
        "    s_train = int(n_train/batch_size)   # Number of training batches\n",
        "\n",
        "    K           = number_of_classes \n",
        "    X_trains    = torch.zeros((s_train, batch_size, *X_train[0].view(-1).shape), requires_grad=False).to(device)\n",
        "    y_trains    = torch.zeros((s_train, batch_size), requires_grad=False).to(device)\n",
        "    if qr_mode:\n",
        "        Qs      = torch.zeros((s_train, *X_train[0].view(-1).shape, batch_size), requires_grad=False).to(device)\n",
        "        Rs      = torch.zeros((s_train, batch_size, batch_size), requires_grad=False).to(device)\n",
        "        print('ðŸ¤–QR started')\n",
        "\n",
        "    for i in range(s_train):\n",
        "        X_trains[i] = X_train[batch_size*i:batch_size*(i+1), :]\n",
        "        y_trains[i] = y_train[batch_size*i:batch_size*(i+1)]\n",
        "        if qr_mode:\n",
        "            Qs[i], Rs[i] = torch.qr(X_trains[i].t())      \n",
        "    \n",
        "    if qr_mode:\n",
        "        print('âœ…QR computed')\n",
        "        return X_trains, y_trains, X_test, y_test, Qs, Rs\n",
        "    else:\n",
        "        return X_trains, y_trains, X_test, y_test\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "     def __init__(self):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(p, 1)\n",
        "     def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "def full_problem_from_batches(Xs, ys):\n",
        "    s_train, batch_size, p = Xs.shape\n",
        "    X = torch.zeros(s_train*batch_size, p)\n",
        "    y = torch.zeros(s_train*batch_size)\n",
        "    for i_batch in range(s_train):\n",
        "        X[batch_size*i_batch:batch_size*(i_batch+1), :] = Xs[i_batch]\n",
        "        y[batch_size*i_batch:batch_size*(i_batch+1)]    = ys[i_batch]\n",
        "    return X, y\n",
        "\n",
        "def model_init(model, parameters_tensor):\n",
        "    new_model = copy.deepcopy(model)\n",
        "    for parameter in new_model.parameters():\n",
        "        parameter.data = parameters_tensor.clone().to(device)\n",
        "        # We won't update bias during the training, since they are not affect the model predictions\n",
        "        break\n",
        "    return new_model\n",
        "\n",
        "\n",
        "def gradient_flow_euler_training(theta_0, X_trains, y_trains,  X_test, y_test, lr, model, final_error = 0.2, epochs_limit = 1000):\n",
        "    X, y        = full_problem_from_batches(X_trains, y_trains)\n",
        "    X, y, X_test, y_test = X.float().to(device), y.float().to(device), X_test.to(device), y_test.to(device)\n",
        "    model = model.to(device)\n",
        "    n_train, p  = X.shape\n",
        "    n_test      = len(y_test)\n",
        "    thetas      = []\n",
        "    losses_train    = []\n",
        "    errors_train    = []\n",
        "    losses_test     = []\n",
        "    errors_test     = []\n",
        "    criterion       = torch.nn.BCELoss()\n",
        "    theta_t         = theta_0\n",
        "    model = model_init(model, theta_0.T)\n",
        "    stop_word = False\n",
        "    N_epochs = 0\n",
        "    while not stop_word:  \n",
        "        N_epochs += 1     \n",
        "        model.zero_grad()\n",
        "        # Forward pass\n",
        "        y_pred = model(X)\n",
        "        loss = criterion(y_pred, y)\n",
        "        # Metrics\n",
        "        model.eval()\n",
        "        thetas.append(theta_t)\n",
        "        losses_train.append(loss.data)\n",
        "        pred_labels         = torch.max(y_pred)[1]\n",
        "        true_labels         = torch.max(y)[1]\n",
        "        train_acc           = true_labels.eq(pred_labels.data).sum().to(dtype=torch.float)/len(true_labels)\n",
        "        errors_train.append(1 - train_acc) \n",
        "        y_pred_test         = model(X_test)\n",
        "        loss_test           = criterion(y_pred_test, y_test)\n",
        "        losses_test.append(loss_test.data)\n",
        "        pred_labels_test    = torch.max(y_pred_test)[1]\n",
        "        true_labels_test    = torch.max(y_test)[1]\n",
        "        test_acc            = true_labels_test.eq(pred_labels_test.data).sum().to(dtype=torch.float)/len(true_labels_test)\n",
        "        errors_test.append(1 - test_acc)\n",
        "        sys.stdout.write('\\r'+f'ðŸ¤– GD error {errors_test[-1]:.3f}/{final_error:.3f} on {N_epochs}-th iteration. Lr {lr}')\n",
        "        if errors_test[-1] <= final_error or N_epochs >= epochs_limit:\n",
        "            stop_word = True\n",
        "            break\n",
        "        # Backward pass \n",
        "        model.train()\n",
        "        loss.backward()\n",
        "        for parameter in model.parameters():\n",
        "            parameter.data = parameter.data - lr*parameter.grad.data\n",
        "            theta_t = np.array((parameter.data.T).cpu())\n",
        "            break\n",
        "            \n",
        "    model.eval()\n",
        "    thetas.append(theta_t)\n",
        "    losses_train.append(loss.data)\n",
        "    pred_labels         = torch.max(y_pred)[1]\n",
        "    true_labels         = torch.max(y)[1]\n",
        "    train_acc           = true_labels.eq(pred_labels.data).sum().to(dtype=torch.float)/len(true_labels)\n",
        "    errors_train.append(1 - train_acc) \n",
        "    y_pred_test = model(X_test)\n",
        "    loss_test   = criterion(y_pred_test, y_test)\n",
        "    losses_test.append(loss_test.data)\n",
        "    pred_labels_test    = torch.max(y_pred_test)[1]\n",
        "    true_labels_test    = torch.max(y_test)[1]\n",
        "    test_acc            = true_labels_test.eq(pred_labels_test.data).sum().to(dtype=torch.float)/len(true_labels_test)\n",
        "    errors_test.append(1 - test_acc)\n",
        "    \n",
        "    print(f'\\nðŸ¤– GD finished with {N_epochs} iterations on lr {lr}')\n",
        "\n",
        "    return N_epochs, thetas, losses_train,losses_test, errors_train, errors_test\n",
        "\n",
        "def sgd_training(theta_0, X_trains, y_trains,  X_test, y_test, lr, model, final_error = 0.2, iter_limit = 1000):\n",
        "    X, y        = full_problem_from_batches(X_trains, y_trains)\n",
        "    X, y, X_test, y_test = X.float().to(device), y.float().to(device), X_test.to(device), y_test.to(device)\n",
        "    model = model.to(device)\n",
        "    s_train, batch_size, p = X_trains.shape\n",
        "    n_train, p  = X.shape\n",
        "    n_test   = len(y_test)\n",
        "    thetas      = []\n",
        "    losses_train    = []\n",
        "    errors_train    = []\n",
        "    losses_test     = []\n",
        "    errors_test     = []\n",
        "    criterion       = torch.nn.BCELoss()\n",
        "    theta_t         = theta_0\n",
        "    model = model_init(model, theta_0.t())\n",
        "    stop_word = False\n",
        "    N_iter = 0\n",
        "    if lr >= 0.2:\n",
        "        iter_limit = 1000\n",
        "    while not stop_word:          \n",
        "        i_batch = N_iter % s_train\n",
        "\n",
        "        if i_batch % 1 == 0:\n",
        "            # Evaluation pass\n",
        "            model.eval()\n",
        "            y_pred = model(X)\n",
        "            loss = criterion(y_pred, y)\n",
        "            thetas.append(theta_t)\n",
        "            losses_train.append(loss.data)\n",
        "            pred_labels     = torch.squeeze(y_pred >= 0.5).float()\n",
        "            train_acc       = y.eq(pred_labels.data).sum().to(dtype=torch.float)/len(pred_labels)\n",
        "            errors_train.append(1 - train_acc) \n",
        "            y_pred_test = model(X_test)\n",
        "            loss_test   = criterion(y_pred_test, y_test.float())\n",
        "            losses_test.append(loss_test.data)\n",
        "            pred_labels_test    = torch.squeeze(y_pred_test >= 0.5).long()\n",
        "            test_acc            = y_test.eq(pred_labels_test.data).sum().to(dtype=torch.float)/len(y_pred_test)\n",
        "            errors_test.append(1 - test_acc)\n",
        "            sys.stdout.write('\\r'+f'ðŸ¤– SGD error {errors_test[-1]:.3f}/{final_error:.3f} on {N_iter}-th iteration. Lr {lr}')\n",
        "            if errors_test[-1] <= final_error:\n",
        "                stop_word = True\n",
        "                break\n",
        "\n",
        "            if N_iter >= iter_limit:\n",
        "                N_iter = None\n",
        "                print(f'\\nðŸ¤– SGD Failed on lr {lr}')\n",
        "                return N_iter, thetas, losses_train,losses_test, errors_train, errors_test\n",
        "\n",
        "        # Backward pass\n",
        "        model.train()\n",
        "        model.zero_grad()\n",
        "        # Forward pass\n",
        "        y_pred = model(X_trains[i_batch])\n",
        "        loss = criterion(y_pred, y_trains[i_batch])\n",
        "        loss.backward()\n",
        "        for parameter in model.parameters():\n",
        "            parameter.data = parameter.data - lr*parameter.grad.data\n",
        "            theta_t = np.array((parameter.data.t()).cpu())\n",
        "            break\n",
        "        N_iter += 1\n",
        "\n",
        "    \n",
        "    print(f'\\nðŸ¤– SGD finished with {N_iter} iterations on lr {lr}')\n",
        "\n",
        "    return N_iter, thetas, losses_train,losses_test, errors_train, errors_test\n",
        "\n",
        "def make_splitting_step(theta_0, Q, R, y, h, n):\n",
        "    h_seq = [0, h]\n",
        "    Q, R, theta_0 = np.array(Q), np.array(R), np.array(theta_0)\n",
        "    eta_0, theta_0 = np.squeeze(Q.T@theta_0), np.squeeze(theta_0)\n",
        "    def rhs(eta, t):\n",
        "        return -1/n * R@(sigmoid(R.T @ eta) - np.array(y))\n",
        "    eta_h = odeint(rhs, eta_0, h_seq)[-1]\n",
        "\n",
        "    theta = Q@(eta_h - eta_0) + theta_0\n",
        "    return torch.from_numpy(theta).reshape(p, 1)\n",
        "\n",
        "def spl_training(theta_0, Qs, Rs, X_trains, y_trains,  X_test, y_test, stepsize, model, final_error = 0.2, iter_limit = 1000):\n",
        "    X, y        = full_problem_from_batches(X_trains, y_trains)\n",
        "    X, y, X_trains, y_trains, X_test, y_test, model = X.float().to(device), y.float().to(device), X_trains.float().to(device), y_trains.float().to(device), X_test.float().to(device), y_test.float().to(device), model.to(device)\n",
        "    s_train, batch_size, p = X_trains.shape\n",
        "    n_train, p  = X.shape\n",
        "    n_test      = len(y_test)\n",
        "    thetas      = []\n",
        "    losses_train    = []\n",
        "    errors_train    = []\n",
        "    losses_test     = []\n",
        "    errors_test     = []\n",
        "    criterion       = torch.nn.BCELoss()\n",
        "    theta_t         = theta_0.to(device)\n",
        "    model = model_init(model, theta_0.t())\n",
        "    stop_word = False\n",
        "    N_iter = 0\n",
        "\n",
        "    if stepsize >= 1000:\n",
        "        iter_limit = 1000\n",
        "    while not stop_word:\n",
        "        i_batch = N_iter % s_train\n",
        "\n",
        "        if i_batch % 1 == 0:      \n",
        "            # Evaluation pass\n",
        "            model.eval()\n",
        "            y_pred = model(X)\n",
        "            loss = criterion(y_pred, y)\n",
        "            thetas.append(theta_t)\n",
        "            losses_train.append(loss.data)\n",
        "            pred_labels     = torch.squeeze(y_pred >= 0.5).float()\n",
        "            train_acc       = y.eq(pred_labels.data).sum().to(dtype=torch.float)/len(pred_labels)\n",
        "            errors_train.append(1 - train_acc) \n",
        "            y_pred_test = model(X_test)\n",
        "            loss_test   = criterion(y_pred_test, y_test)\n",
        "            losses_test.append(loss_test.data)\n",
        "            pred_labels_test    = torch.squeeze(y_pred_test >= 0.5).float()\n",
        "            test_acc            = y_test.eq(pred_labels_test.data).sum().to(dtype=torch.float)/len(y_pred_test)\n",
        "            errors_test.append(1 - test_acc)\n",
        "            sys.stdout.write('\\r'+f'ðŸ¤– Splitting error {errors_test[-1]:.3f}/{final_error:.3f} on {N_iter}-th iteration. Stepsize {stepsize}')\n",
        "            if errors_test[-1] <= final_error:\n",
        "                stop_word = True\n",
        "                break\n",
        "\n",
        "            if N_iter >= iter_limit:\n",
        "                N_iter = None\n",
        "                print(f'\\nðŸ¤– Splitting Failed on lr {lr}')\n",
        "                return N_iter, thetas, losses_train,losses_test, errors_train, errors_test\n",
        "\n",
        "        # Backward pass\n",
        "        model.train()\n",
        "        theta_t = make_splitting_step(theta_t.cpu(), Qs[i_batch].cpu(), Rs[i_batch].cpu(), y_trains[i_batch].cpu(), stepsize, n_train).to(dtype=torch.float)\n",
        "        model = model_init(model, theta_t.t())\n",
        "        N_iter += 1  \n",
        "\n",
        "    print(f'\\nðŸ¤– Splitting finished with {N_iter} iterations on Stepsize {stepsize}')\n",
        "\n",
        "    return N_iter, thetas, losses_train,losses_test, errors_train, errors_test\n",
        "\n",
        "def plot_convergence_from_lr_time(learning_rates, list_of_methods, list_of_labels):\n",
        "    colors = ['g', 'r']\n",
        "    color_labels = ['^', 'o']\n",
        "    plt.figure(figsize = (3.5,2.5))\n",
        "    for method, label, color, col_lab in zip(list_of_methods, list_of_labels, colors, color_labels):\n",
        "        mean    = np.zeros(len(learning_rates))\n",
        "        std     = np.zeros(len(learning_rates))\n",
        "\n",
        "        for i_lr, lr in enumerate(learning_rates):\n",
        "            if any(method[:, i_lr]) == None:\n",
        "                mean[i_lr] = None\n",
        "                std[i_lr]  = None\n",
        "            else:\n",
        "                mean[i_lr] = np.mean(method[:, i_lr])\n",
        "                std[i_lr]  = np.std(method[:, i_lr])\n",
        "        plt.loglog(learning_rates, mean, color+col_lab, label = label)\n",
        "        plt.loglog(learning_rates, mean, color+':')\n",
        "        plt.fill_between(learning_rates, mean-std, mean+std, color=color, alpha=0.1)\n",
        "        plt.grid(True,which=\"both\", linestyle='--', linewidth=0.4)\n",
        "        # plt.grid()\n",
        "        plt.xlabel('Learning rate')\n",
        "        plt.ylabel('Time to converge')\n",
        "        plt.legend()\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_convergence_from_lr(learning_rates, list_of_methods, list_of_labels):\n",
        "    colors = ['g', 'r']\n",
        "    color_labels = ['^', 'o']\n",
        "    plt.figure(figsize = (3.5,2.5))\n",
        "    for method, label, color, col_lab in zip(list_of_methods, list_of_labels, colors, color_labels):\n",
        "        mean    = np.zeros(len(learning_rates))\n",
        "        std     = np.zeros(len(learning_rates))\n",
        "\n",
        "        for i_lr, lr in enumerate(learning_rates):\n",
        "            if any(method[:, i_lr]) == None:\n",
        "                mean[i_lr] = None\n",
        "                std[i_lr]  = None\n",
        "            else:\n",
        "                mean[i_lr] = np.mean(method[:, i_lr])\n",
        "                std[i_lr]  = np.std(method[:, i_lr])\n",
        "        std     = np.std(method, axis = 0)   \n",
        "        plt.loglog(learning_rates, mean, color+col_lab, label = label)\n",
        "        plt.loglog(learning_rates, mean, color+':')\n",
        "        plt.fill_between(learning_rates, mean-std, mean+std, color=color, alpha=0.1)\n",
        "        plt.grid(True,which=\"both\", linestyle='--', linewidth=0.4)\n",
        "        # plt.grid()\n",
        "        plt.xlabel('Learning rate')\n",
        "        plt.ylabel('Iterations to converge')\n",
        "        plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}